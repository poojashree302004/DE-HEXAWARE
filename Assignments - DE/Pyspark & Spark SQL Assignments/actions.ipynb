{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"17IorK48JQAxAzQJHprV2Am5-nL6auilW","authorship_tag":"ABX9TyPUVXDCAm+c2IU+W/GMWZGn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TOoGsorBqnGc","executionInfo":{"status":"ok","timestamp":1754019830808,"user_tz":-330,"elapsed":20280,"user":{"displayName":"Pooja Shree M","userId":"17238665722091243740"}},"outputId":"341f3fb5-c05a-4e70-ad15-5cbb0d8fe8a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 2, 3, 4, 5]\n","5\n","15\n","120\n","[1, 2, 3]\n","1\n"]}],"source":["import io\n","import pandas as pd\n","import pyspark\n","#Importing the Libraries\n","from pyspark import SparkContext\n","from pyspark.sql import SparkSession\n","sc = SparkContext.getOrCreate()\n","rdd = sc.parallelize([1,2,3,4,5])\n","\n","print(rdd.collect())\n","print(rdd.count())\n","print(rdd.reduce(lambda x,y : x+y))\n","print(rdd.reduce(lambda x,y : x*y))\n","print(rdd.take(3))\n","print(rdd.first())\n","# print(rdd.saveAsTextFile(\"ActionsPractice.txt\"))\n","\n"]},{"cell_type":"code","source":["import io\n","import pandas as pd\n","import pyspark\n","from pyspark import SparkContext\n","\n","# Initialize SparkContext\n","sc = SparkContext.getOrCreate()\n","\n","# Sample RDD\n","rdd = sc.parallelize([1, 2, 3, 4, 5])\n","\n","print(\"Collect:\", rdd.collect())\n","print(\"Count:\", rdd.count())\n","print(\"Reduce (sum):\", rdd.reduce(lambda x, y: x + y))\n","print(\"Reduce (product):\", rdd.reduce(lambda x, y: x * y))\n","print(\"Take(3):\", rdd.take(3))\n","print(\"First:\", rdd.first())\n","print(\"Min:\", rdd.min())\n","print(\"Max:\", rdd.max())\n","print(\"TakeSample(False, 3):\", rdd.takeSample(False, 3))\n","print(\"Top(3):\", rdd.top(3))\n","print(\"TakeOrdered(3):\", rdd.takeOrdered(3))\n","print(\"CountByValue:\", dict(rdd.countByValue()))\n","print(\"Fold (sum):\", rdd.fold(0, lambda x, y: x + y))\n","print(\"Aggregate (sum):\", rdd.aggregate(0, lambda x, y: x + y, lambda x, y: x + y))\n","print(\"Sum:\", rdd.sum())\n","print(\"Mean:\", rdd.mean())\n","print(\"Stdev:\", rdd.stdev())\n","print(\"Variance:\", rdd.variance())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_esZCLcS6Vek","executionInfo":{"status":"ok","timestamp":1753955811592,"user_tz":-330,"elapsed":6633,"user":{"displayName":"Pooja Shree M","userId":"17238665722091243740"}},"outputId":"539bdbf2-036b-44a4-92fc-6f51f1931391"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collect: [1, 2, 3, 4, 5]\n","Count: 5\n","Reduce (sum): 15\n","Reduce (product): 120\n","Take(3): [1, 2, 3]\n","First: 1\n","Min: 1\n","Max: 5\n","TakeSample(False, 3): [5, 2, 1]\n","Top(3): [5, 4, 3]\n","TakeOrdered(3): [1, 2, 3]\n","CountByValue: {1: 1, 2: 1, 3: 1, 4: 1, 5: 1}\n","Fold (sum): 15\n","Aggregate (sum): 15\n","Sum: 15\n","Mean: 3.0\n","Stdev: 1.4142135623730951\n","Variance: 2.0\n"]}]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","spark =SparkSession.builder.appName(\"Practice\").getOrCreate()\n","df_pyspark= spark.read.csv(\"/Employee_Salary_Dataset.csv\",header=True,inferSchema=True)\n","df_pyspark.show()\n","df_pyspark.groupBy(\"Gender\").sum(\"salary\").show()\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enOZBVaRVP07","executionInfo":{"status":"ok","timestamp":1754019893458,"user_tz":-330,"elapsed":9691,"user":{"displayName":"Pooja Shree M","userId":"17238665722091243740"}},"outputId":"34d91bcc-31e5-481b-cf92-46ff82f9d219"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+----------------+---+------+-------+\n","| ID|Experience_Years|Age|Gender| Salary|\n","+---+----------------+---+------+-------+\n","|  1|               5| 28|Female| 250000|\n","|  2|               1| 21|  Male|  50000|\n","|  3|               3| 23|Female| 170000|\n","|  4|               2| 22|  Male|  25000|\n","|  5|               1| 17|  Male|  10000|\n","|  6|              25| 62|  Male|5001000|\n","|  7|              19| 54|Female| 800000|\n","|  8|               2| 21|Female|   9000|\n","|  9|              10| 36|Female|  61500|\n","| 10|              15| 54|Female| 650000|\n","| 11|               4| 26|Female| 250000|\n","| 12|               6| 29|  Male|1400000|\n","| 13|              14| 39|  Male|6000050|\n","| 14|              11| 40|  Male| 220100|\n","| 15|               2| 23|  Male|   7500|\n","| 16|               4| 27|Female|  87000|\n","| 17|              10| 34|Female| 930000|\n","| 18|              15| 54|Female|7900000|\n","| 19|               2| 21|  Male|  15000|\n","| 20|              10| 36|  Male| 330000|\n","+---+----------------+---+------+-------+\n","only showing top 20 rows\n","\n","+------+-----------+\n","|Gender|sum(salary)|\n","+------+-----------+\n","|Female|   36988500|\n","|  Male|   35081650|\n","+------+-----------+\n","\n"]}]},{"cell_type":"code","source":["df_pyspark.groupBy(\"Experience_Years\").min(\"salary\").show(5)\n","df_pyspark.groupBy(\"Experience_Years\").max(\"salary\").show(5)\n","df_pyspark.groupBy(\"Experience_Years\").avg(\"salary\").show(5)\n","df_pyspark.groupBy(\"Experience_Years\").mean(\"salary\").show(5)\n","df_pyspark.groupBy(\"Experience_Years\").count().show(5)  #count of number of people in each Department\n","df_pyspark.groupBy(\"ID\",\"Experience_Years\").sum(\"salary\").show(5)\n","df_pyspark.groupBy(\"Experience_Years\").agg(({\"salary\":\"sum\"})).show(5)\n","df_pyspark.agg(({\"salary\":\"sum\"})).show(5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7kCnl8ZzYlUC","executionInfo":{"status":"ok","timestamp":1753964374461,"user_tz":-330,"elapsed":2901,"user":{"displayName":"Pooja Shree M","userId":"17238665722091243740"}},"outputId":"0b578b09-29cb-47a9-b969-26126ecb743b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------+-----------+\n","|Experience_Years|min(salary)|\n","+----------------+-----------+\n","|              27|   10000000|\n","|               1|       3000|\n","|               6|    1400000|\n","|              16|    7600000|\n","|               3|      20000|\n","+----------------+-----------+\n","only showing top 5 rows\n","\n","+----------------+-----------+\n","|Experience_Years|max(salary)|\n","+----------------+-----------+\n","|              27|   10000000|\n","|               1|      50000|\n","|               6|    1400000|\n","|              16|    7600000|\n","|               3|     170000|\n","+----------------+-----------+\n","only showing top 5 rows\n","\n","+----------------+-----------+\n","|Experience_Years|avg(salary)|\n","+----------------+-----------+\n","|              27|      1.0E7|\n","|               1|    17250.0|\n","|               6|  1400000.0|\n","|              16|  7600000.0|\n","|               3|    95000.0|\n","+----------------+-----------+\n","only showing top 5 rows\n","\n","+----------------+-----------+\n","|Experience_Years|avg(salary)|\n","+----------------+-----------+\n","|              27|      1.0E7|\n","|               1|    17250.0|\n","|               6|  1400000.0|\n","|              16|  7600000.0|\n","|               3|    95000.0|\n","+----------------+-----------+\n","only showing top 5 rows\n","\n","+----------------+-----+\n","|Experience_Years|count|\n","+----------------+-----+\n","|              27|    1|\n","|               1|    4|\n","|               6|    1|\n","|              16|    1|\n","|               3|    2|\n","+----------------+-----+\n","only showing top 5 rows\n","\n","+---+----------------+-----------+\n","| ID|Experience_Years|sum(salary)|\n","+---+----------------+-----------+\n","|  9|              10|      61500|\n","|  6|              25|    5001000|\n","| 19|               2|      15000|\n","| 10|              15|     650000|\n","| 14|              11|     220100|\n","+---+----------------+-----------+\n","only showing top 5 rows\n","\n","+----------------+-----------+\n","|Experience_Years|sum(salary)|\n","+----------------+-----------+\n","|              27|   10000000|\n","|               1|      69000|\n","|               6|    1400000|\n","|              16|    7600000|\n","|               3|     190000|\n","+----------------+-----------+\n","only showing top 5 rows\n","\n","+-----------+\n","|sum(salary)|\n","+-----------+\n","|   72070150|\n","+-----------+\n","\n"]}]},{"cell_type":"code","source":["import io\n","import pandas as pd\n","import pyspark\n","from pyspark import SparkContext\n","\n","# Initialize SparkContext\n","sc = SparkContext.getOrCreate()\n","marks_rdd = sc.parallelize([('Rahul', 25), ('Swati', 26), ('Rohan', 22), ('Rahul', 23), ('Swati', 19), ('Shreya', 28), ('Abhay', 26), ('Rohan', 22)])\n","dict_rdd = marks_rdd.countByKey().items()\n","for key, value in dict_rdd:\n","    print(key, value)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDxRaYXKMKvM","executionInfo":{"status":"ok","timestamp":1754044792777,"user_tz":-330,"elapsed":13887,"user":{"displayName":"Pooja Shree M","userId":"17238665722091243740"}},"outputId":"a41679e9-94f9-4a28-a632-d40b854664fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Rahul 2\n","Swati 2\n","Rohan 2\n","Shreya 1\n","Abhay 1\n"]}]}]}