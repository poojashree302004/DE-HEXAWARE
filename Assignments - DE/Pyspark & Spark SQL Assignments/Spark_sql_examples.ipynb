{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "kqZsprJf3_Rr"
      },
      "source": [
        "\n",
        "## Overview\n",
        "\n",
        "This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n",
        "\n",
        "This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "WzxucMIS3_Rz",
        "outputId": "550f7397-e6c6-4c7c-a953-89e7a9072732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col,concat,lit,floor,rand\n",
        "spark = SparkSession.builder.appName(\"SparkSQLPractice\").getOrCreate()\n",
        "# File location and type\n",
        "file_location = \"/content/simple-zipcodes.csv\"\n",
        "file_type = \"csv\"\n",
        "\n",
        "# CSV options\n",
        "infer_schema = \"false\"\n",
        "first_row_is_header = \"false\"\n",
        "delimiter = \",\"\n",
        "\n",
        "# The applied options are for CSV files. For other file types, these will be ignored.\n",
        "df = spark.read.format(file_type) \\\n",
        "  .option(\"inferSchema\", infer_schema) \\\n",
        "  .option(\"header\", first_row_is_header) \\\n",
        "  .option(\"sep\", delimiter) \\\n",
        "  .load(file_location)\n",
        "\n",
        "display(df)\n",
        "df.createOrReplaceTempView(\"tempdata\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "implicitDf": true,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b5f66379-6f7f-42ec-8e82-d0e0926a1721",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "DgbPbR053_R3",
        "outputId": "746ec4b0-01c0-4db5-f43d-7c8db646b638",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+-------------------+-------+-----+\n",
            "|         _c0|    _c1|                _c2|    _c3|  _c4|\n",
            "+------------+-------+-------------------+-------+-----+\n",
            "|RecordNumber|Country|               City|Zipcode|State|\n",
            "|           1|     US|        PARC PARQUE|    704|   PR|\n",
            "|           2|     US|PASEO COSTA DEL SUR|    704|   PR|\n",
            "|          10|     US|       BDA SAN LUIS|    709|   PR|\n",
            "|       49347|     US|               HOLT|  32564|   FL|\n",
            "|       49348|     US|          HOMOSASSA|  34487|   FL|\n",
            "|       61391|     US|  CINGULAR WIRELESS|  76166|   TX|\n",
            "|       61392|     US|         FORT WORTH|  76177|   TX|\n",
            "|       61393|     US|           FT WORTH|  76177|   TX|\n",
            "|       54356|     US|        SPRUCE PINE|  35585|   AL|\n",
            "|       76511|     US|           ASH HILL|  27007|   NC|\n",
            "|           4|     US|    URB EUGENE RICE|    704|   PR|\n",
            "|       39827|     US|               MESA|  85209|   AZ|\n",
            "|       39828|     US|               MESA|  85210|   AZ|\n",
            "|       49345|     US|           HILLIARD|  32046|   FL|\n",
            "|       49346|     US|             HOLDER|  34445|   FL|\n",
            "|           3|     US|      SECT LANAUSSE|    704|   PR|\n",
            "|       54354|     US|      SPRING GARDEN|  36275|   AL|\n",
            "|       54355|     US|        SPRINGVILLE|  35146|   AL|\n",
            "|       76512|     US|           ASHEBORO|  27203|   NC|\n",
            "+------------+-------+-------------------+-------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------------+-------+\n",
            "|         _c0|    _c1|\n",
            "+------------+-------+\n",
            "|RecordNumber|Country|\n",
            "|           1|     US|\n",
            "|           2|     US|\n",
            "|          10|     US|\n",
            "|       49347|     US|\n",
            "+------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select * from tempdata\").show()\n",
        "df.select(\"_c0\",\"_c1\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "86b42761-2dfd-4282-9fc5-0fbacd6dde09",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "skns79Aj3_R4",
        "outputId": "d48656fb-be7c-4d31-c676-4a73adf761db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----+-----+---+\n",
            "|  _c0|_c1| _c2|  _c3|_c4|\n",
            "+-----+---+----+-----+---+\n",
            "|39827| US|MESA|85209| AZ|\n",
            "|39828| US|MESA|85210| AZ|\n",
            "+-----+---+----+-----+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"SELECT * From tempdata WHERE _c4='AZ'\"\"\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "23dca3dc-ca46-49bd-95e8-be0251419aa9",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Qn-wNAl03_R6",
        "outputId": "7be43c33-8808-481d-b613-77c460618d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[RecordNumber: string, Country: string, City: string, Zipcode: string, State: string]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# File location and type\n",
        "file_location = \"/content/simple-zipcodes.csv\"\n",
        "file_type = \"csv\"\n",
        "\n",
        "# CSV options\n",
        "infer_schema = \"false\"\n",
        "first_row_is_header = \"true\"\n",
        "delimiter = \",\"\n",
        "\n",
        "# The applied options are for CSV files. For other file types, these will be ignored.\n",
        "df = spark.read.format(file_type) \\\n",
        "  .option(\"inferSchema\", infer_schema) \\\n",
        "  .option(\"header\", first_row_is_header) \\\n",
        "  .option(\"sep\", delimiter) \\\n",
        "  .load(file_location)\n",
        "\n",
        "display(df)\n",
        "df.createOrReplaceTempView(\"customer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4867ca65-fa07-45d9-84c2-f4c50d33b0e9",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "PmEcZEu43_R8",
        "outputId": "ce8f95f9-d3cf-4dab-9db1-f1db783a0a25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+-------------------+-------+-----+\n",
            "|RecordNumber|Country|               City|Zipcode|State|\n",
            "+------------+-------+-------------------+-------+-----+\n",
            "|           1|     US|        PARC PARQUE|    704|   PR|\n",
            "|           2|     US|PASEO COSTA DEL SUR|    704|   PR|\n",
            "|          10|     US|       BDA SAN LUIS|    709|   PR|\n",
            "|       49347|     US|               HOLT|  32564|   FL|\n",
            "|       49348|     US|          HOMOSASSA|  34487|   FL|\n",
            "|       61391|     US|  CINGULAR WIRELESS|  76166|   TX|\n",
            "|       61392|     US|         FORT WORTH|  76177|   TX|\n",
            "|       61393|     US|           FT WORTH|  76177|   TX|\n",
            "|       54356|     US|        SPRUCE PINE|  35585|   AL|\n",
            "|       76511|     US|           ASH HILL|  27007|   NC|\n",
            "|           4|     US|    URB EUGENE RICE|    704|   PR|\n",
            "|       39827|     US|               MESA|  85209|   AZ|\n",
            "|       39828|     US|               MESA|  85210|   AZ|\n",
            "|       49345|     US|           HILLIARD|  32046|   FL|\n",
            "|       49346|     US|             HOLDER|  34445|   FL|\n",
            "|           3|     US|      SECT LANAUSSE|    704|   PR|\n",
            "|       54354|     US|      SPRING GARDEN|  36275|   AL|\n",
            "|       54355|     US|        SPRINGVILLE|  35146|   AL|\n",
            "|       76512|     US|           ASHEBORO|  27203|   NC|\n",
            "|       76513|     US|           ASHEBORO|  27204|   NC|\n",
            "+------------+-------+-------------------+-------+-----+\n",
            "\n",
            "+------------+-------+\n",
            "|RecordNumber|Country|\n",
            "+------------+-------+\n",
            "|           1|     US|\n",
            "|           2|     US|\n",
            "|          10|     US|\n",
            "|       49347|     US|\n",
            "|       49348|     US|\n",
            "+------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select * from customer\").show()\n",
        "df.select(\"RecordNumber\",\"Country\").show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "fedbf165-f621-489f-ab1e-5cd08aa4fd22",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "RTDn-wuJ3_SA",
        "outputId": "1379de0d-52e4-483e-b53a-56a5a8311944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+-------------------+-------+-----+\n",
            "|RecordNumber|Country|               City|Zipcode|State|\n",
            "+------------+-------+-------------------+-------+-----+\n",
            "|           1|     US|        PARC PARQUE|    704|   PR|\n",
            "|           2|     US|PASEO COSTA DEL SUR|    704|   PR|\n",
            "|          10|     US|       BDA SAN LUIS|    709|   PR|\n",
            "|           4|     US|    URB EUGENE RICE|    704|   PR|\n",
            "|           3|     US|      SECT LANAUSSE|    704|   PR|\n",
            "+------------+-------+-------------------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"SELECT * From customer WHERE state='PR'\"\"\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6494d2cb-210a-46dc-998e-771e94bf0b39",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "NGHSRVaA3_SD",
        "outputId": "3d122152-dc4e-4e3e-c04b-ba70d5ec449e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+-------------------+-------+-----+\n",
            "|RecordNumber|Country|               City|Zipcode|State|\n",
            "+------------+-------+-------------------+-------+-----+\n",
            "|       39827|     US|               MESA|  85209|   AZ|\n",
            "|       39828|     US|               MESA|  85210|   AZ|\n",
            "|       49347|     US|               HOLT|  32564|   FL|\n",
            "|       49348|     US|          HOMOSASSA|  34487|   FL|\n",
            "|       49345|     US|           HILLIARD|  32046|   FL|\n",
            "|       49346|     US|             HOLDER|  34445|   FL|\n",
            "|           1|     US|        PARC PARQUE|    704|   PR|\n",
            "|           2|     US|PASEO COSTA DEL SUR|    704|   PR|\n",
            "|          10|     US|       BDA SAN LUIS|    709|   PR|\n",
            "|           4|     US|    URB EUGENE RICE|    704|   PR|\n",
            "+------------+-------+-------------------+-------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"select * FROM customer WHERE state in ('PR','AZ','FL')order by state \"\"\").show(10\n",
        "                                                                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "be5b15e9-0587-4f43-926e-b64ac699e8f8",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Ul17km1-3_SF",
        "outputId": "60acd515-f290-422b-bbb0-ec4a3225e768",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+\n",
            "|state|count|\n",
            "+-----+-----+\n",
            "|   AZ|    2|\n",
            "|   NC|    3|\n",
            "|   AL|    3|\n",
            "|   TX|    3|\n",
            "|   FL|    4|\n",
            "|   PR|    5|\n",
            "+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"SELECT state,count(*) as count FROM customer GROUP BY state\"\"\").show()"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {
        "mostRecentlyExecutedCommandWithImplicitDF": {
          "commandId": -1,
          "dataframes": [
            "_sqldf"
          ]
        },
        "pythonIndentUnit": 4
      },
      "notebookName": "Spark sql examples",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}